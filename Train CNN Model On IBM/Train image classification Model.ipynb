{"cells": [{"metadata": {}, "cell_type": "code", "source": "pwd", "execution_count": 1, "outputs": [{"output_type": "execute_result", "execution_count": 1, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install tensorflow==2.7.1\n!pip install keras==2.2.4", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: tensorflow==2.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (2.7.1)\nRequirement already satisfied: wheel<1.0,>=0.32.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (0.37.0)\nRequirement already satisfied: gast<0.5.0,>=0.2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (0.4.0)\nRequirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (1.1.2)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (0.23.1)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (0.2.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (4.1.1)\nRequirement already satisfied: numpy>=1.14.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (1.20.3)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (1.12.1)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (1.15.0)\nRequirement already satisfied: absl-py>=0.4.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (0.12.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (1.6.3)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (3.19.1)\nRequirement already satisfied: keras<2.8,>=2.7.0rc0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (2.7.0)\nRequirement already satisfied: libclang>=9.0.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (14.0.6)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (3.3.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (3.2.1)\nRequirement already satisfied: flatbuffers<3.0,>=1.12 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (1.42.0)\nRequirement already satisfied: tensorboard~=2.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (2.7.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (1.1.0)\nRequirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow==2.7.1) (2.7.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow==2.7.1) (1.23.0)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow==2.7.1) (2.26.0)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow==2.7.1) (0.6.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow==2.7.1) (1.6.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow==2.7.1) (58.0.4)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow==2.7.1) (2.0.2)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow==2.7.1) (0.4.4)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.6->tensorflow==2.7.1) (3.3.3)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.1) (4.2.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.1) (4.7.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.1) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.1) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.1) (0.4.8)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.1) (2.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.1) (2022.9.24)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.1) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.1) (1.26.7)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.1) (3.2.1)\nCollecting keras==2.2.4\n  Using cached Keras-2.2.4-py2.py3-none-any.whl (312 kB)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.7.3)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.1.2)\nRequirement already satisfied: h5py in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (3.2.1)\nRequirement already satisfied: pyyaml in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (5.4.1)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.15.0)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.0.8)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.20.3)\nInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 2.7.0\n    Uninstalling keras-2.7.0:\n      Successfully uninstalled keras-2.7.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.7.1 requires keras<2.8,>=2.7.0rc0, but you have keras 2.2.4 which is incompatible.\u001b[0m\nSuccessfully installed keras-2.2.4\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from tensorflow.keras.preprocessing.image import ImageDataGenerator", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "2022-11-16 07:53:41.077383: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ibm/dsdriver/lib:/opt/oracle/lib:/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow\nUsing TensorFlow backend.\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "code", "source": "# Training Datagen\ntrain_datagen = ImageDataGenerator(rescale=1/255,zoom_range=0.2,horizontal_flip=True,vertical_flip=False)\n# Testing Datagen\ntest_datagen = ImageDataGenerator(rescale=1/255)", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='qMbxf8UO34fapSRVfoIX0yJbaLb5pHpHi-HRESsGKPmh',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.ap.cloud-object-storage.appdomain.cloud')\n\nbucket = 'realtimecommunicationsystempowere-donotdelete-pr-ne0yo08hakvd76'\nobject_key = 'conversation engine for deaf and dumb.zip'\n\nstreaming_body_1 = cos_client.get_object(Bucket=bucket, Key=object_key)['Body']\n\n# Your data file was loaded into a botocore.response.StreamingBody object.\n# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n# pandas documentation: http://pandas.pydata.org/\n", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Unzip the Dataset Zip File\nfrom io import BytesIO\nimport zipfile\nunzip = zipfile.ZipFile(BytesIO(streaming_body_1.read()), 'r')\nfile_paths = unzip.namelist()\nfor path in file_paths:\n    unzip.extract(path)", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%%bash\nls Communication_Dataset", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "test_set\ntraining_set\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Training Dataset\nx_train=train_datagen.flow_from_directory(r'/home/wsuser/work/Communication_Dataset/training_set',target_size=(64,64), class_mode='categorical',batch_size=900)\n# Testing Dataset\nx_test=test_datagen.flow_from_directory(r'/home/wsuser/work/Communication_Dataset/test_set',target_size=(64,64), class_mode='categorical',batch_size=900)", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "Found 27000 images belonging to 9 classes.\nFound 25737 images belonging to 9 classes.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "print(\"Len x-train : \", len(x_train))\nprint(\"Len x-test : \", len(x_test))", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "Len x-train :  30\nLen x-test :  29\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# The Class Indices in Training Dataset\nx_train.class_indices", "execution_count": 12, "outputs": [{"output_type": "execute_result", "execution_count": 12, "data": {"text/plain": "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "# Importing Libraries\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense", "execution_count": 13, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Creating Model\nmodel=Sequential()", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "2022-11-16 07:56:52.259941: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ibm/dsdriver/lib:/opt/oracle/lib:/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow\n2022-11-16 07:56:52.260029: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "code", "source": "# Adding Layers\nmodel.add(Convolution2D(32,(3,3),activation='relu',input_shape=(64,64,3)))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Flatten())\n\n# Adding Hidden Layers\nmodel.add(Dense(300,activation='relu'))\nmodel.add(Dense(150,activation='relu'))\n\n# Adding Output Layer\nmodel.add(Dense(9,activation='softmax'))", "execution_count": 15, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Compiling the Model\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Fitting the Model Generator\nmodel.fit_generator(x_train,steps_per_epoch=len(x_train),epochs=10,validation_data=x_test,validation_steps=len(x_test))", "execution_count": null, "outputs": [{"output_type": "stream", "text": "/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:1963: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n  warnings.warn('`Model.fit_generator` is deprecated and '\n", "name": "stderr"}, {"output_type": "stream", "text": "Epoch 1/10\n30/30 [==============================] - ETA: 0s - loss: 2.5305 - accuracy: 0.1468 ", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "model.save('IBM_Communication_Model.h5')\n# Current accuracy is 0.8154", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Convert the Saved Model to a Tar Compressed Format\n!tar -zcvf IBM_TrainedModel.tgz IBM_Communication_Model.h5", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "%%bash\nls -ll", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "!pip install watson-machine-learning-client --upgrade", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning import APIClient\nwml_credentials = {\n    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n    \"apikey\": \"mNVF7E95G-awR213njShj1GiUfN-1SpPq-ko8Wx7na1-\"\n}\n\nclient = APIClient(wml_credentials)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def guid_from_space_name(client, space_name):\n    space = client.spaces.get_details()\n    return (next(item for item in space['resources'] if item['entity'][\"name\"] == space_name)['metadata']['id'])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}